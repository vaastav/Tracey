\section{Introduction}

Distributed systems are prevalent in society to the extent that billions of people either directly or 
indirectly depend on the correct functioning of a distributed system. From banking applications to social
networks, from large-scale data analytics to online video streaming, from web searches to cryptocurrencies,
most of the successful computing applications of today are powered by distributed systems.
The meteoric rise of cloud computing in the past decade has only increased our dependence on these
distributed systems in our lives.

Tasks like monitoring, root cause analysis, performance comprehension require techniques that cut across component,
system, and machine boundaries to collect, correlate, and integrate data. In the past decade, distributed tracing has emerged as an effective way to gain visibility across distributed systems~\cite{mace2015pivot,mace2018universal,fonseca2007xtrace}.  
Today distributed tracing frameworks are deployed at all major internet companies~\cite{kaldor2017canopy,sigelman2010dapper,netflixtracing}; 
notable open-source examples include OpenTelemetry~\cite{opentelemetry}, Jaeger~\cite{jaeger}, and Zipkin~\cite{zipkin}; and 
observability-focused companies offer platforms centered on analysis of traces~\cite{lightstep}.

Distributed tracing tools arose out of a need to understand the behavior of \emph{individual requests}: identifying the specific services 
invoked by a request, diagnosing problematic requests, and debugging correctness issues~\cite{fonseca2007xtrace,sigelman2010dapper,macewe}.
As a result, each trace only tells the story of a single request.
A trace represents the path of one request through the system and contains information such as the timing of requests, 
the events executed, and the nodes where these events were executed. Moreover, traces can be used
to identify slow requests and understand the difference between request executions. 

However, as distributed tracing is designed for production distributed systems, a large volume of data
is produced on a daily basis. It is humanly impossible to manually analyze each trace and draw inference
about the system as a collective. Current analysis tools primarily focus on visualzing a single trace
and provide little help to the user for analyzing a large amount of data. We intend to remove this burden
by automatically generating a daily summary that presents the developers with the daily highlights
across the trace data.

In this project, we propose to create an NLP tool that uses data from traces to succinctly summarize
the traces that were generated in a given day to provide an informative summary to the developer
in-charge of maintaining the health and performance of the system. We believe, generating a daily summary
would alleviate some burden from the developers in terms of the sheer volume of data they need to analyze
as well as potentially provide hints regarding the sources of performance or correctness issues.