\section{Contribution}
\label{sec:contribution}

\subsection{Trace2Text}

The task of text generation from data can be divided into 
three modular interdependent tasks - (i) \emph{content planning}
defines which parts of the input fields or meaning representations
should be selected; (ii) \emph{sentence planning} determines
which selected fields are to be dealt with in each output sentence;
and (iii) \emph{surface realization} generates those sentences.
To obtain processed trace data, we use a backend server
for trace processing that we had built as part of the visualization
course last semester\footnote{The source code of the backend server is located at \url{https://github.com/vaastav/TraViz/tree/master/traviz_backend}}.
The input data for each trace includes, some overview information of the trace,
the list of events, and the list of tasks for that trace. 
For each event, the human annotated-text as well as the probability of that event occurring
is included.
For each task, a list of concurrent tasks that were happening during the task's execution
are also included. \emph{The goal is to generate a text representation of the trace
that includes information describing the execution of the trace and overview information
that would be useful for the user.}

% escapechar sets the escape character that we can use to exit into latex mode.
\begin{lstlisting}[caption={Annotated overview paragraph generated for a trace},captionpos=b,label={fig:trace_owtext}, escapechar=\#]
#\circled{1}# The trace was created on 31 May, 2019 and it took around 422 seconds to complete.
#\circled{2}# The trace was associated with the following tags: ComposePost NginxWebServer5.
#\circled{3}# The trace had 388 events, out of which 28 events had less than 25.0 chance of occurring.
#\circled{4}# The execution of the request was performed by 22 tasks. 3 tasks had latency that ranked higher than the 95th percentile of the latency distribution for the respective task. 
#\circled{5}# Task performing the operation UrlShortenHandler::UploadUrlsMongoInsert had the maximum amount of contention with 7 other tasks performing the same operation at the same time for different requests.
\end{lstlisting}

\fakepara{Content Planning} The content planner parses the input data to extract the information
needed to generate the overview text and the execution text. From the list of events, the number
of anomalous events are extracted. An anomalous event is an event that has probability lower
than a pre-defined threshold. The content planner also constructs a Directed Acyclic Graph
of the events based on the causal relationships of the events. For each task in the list of tasks,
an array of temporally ordered events are created that occurred on that task. The task with most number of
concurrent tasks is also extracted.

\fakepara{Sentence Planning} The sentence planner separates the content by planning to generate one paragraph
for each task in the trace as well as one paragraph for overview information about the trace.
The information contained inside the paragraph would be the name of the task that created this task
and labels from the events associated with the task.
The overview paragraph provides overview information about the trace such as latency, tags, and other metadata.
It also includes information about anomalous events and tasks.

\fakepara{Surface Realization} The surface realization is currently static as it is done based on
a pre-defined template. \autoref{fig:trace_owtext} shows an annotated example of the overview paragraph generated for a trace.
\circled{1} provides information about when the trace was created and what was the latency of the task.
\circled{2} mentions the tags associated with the trace.
\circled{3} contains the total number of events in the trace and the number of anomalous events. 
\circled{4} has the number of tasks in the trace and the number of tasks which have latencies that lie in the 95th percentile of the latency distributions
of their respective tasks. 
\circled{5} provides the name of the task that had the most number of concurrent tasks executing at the same time.
\autoref{fig:trace_tasktext} shows an annotated example of the paragraph generated for a task in a trace.
\circled{1} describes which task, if any, created this particular task.
\circled{2} is the name of the task.
Each sentence following \circled{2} is the human-annotated label of the corresponding event that occurred on that task.
The sentences are ordered w.r.t to the ordering of the events for that task.

% escapechar sets the escape character that we can use to exit into latex mode.
\begin{lstlisting}[caption={Annotated paragraph generated for a task in a trace},captionpos=b,label={fig:trace_tasktext}, escapechar=\#]
#\circled{1}# Task NginxWebServer created task MediaHandler::UploadMedia. 
#\circled{2}# MediaHandler::UploadMedia. 
Uploading media to compose post service. Popping client from client pool. Obtaining lock on client pool mutex. Obtained lock on client pool mutex. No client available in client pool. Creating a new client. Releasing lock on client pool mutex. Connecting to client. Pushing a client into client pool. Acquiring lock on mutex. Acquired lock on mutex. Pushing client back into client pool. Releasing lock on mutex. MediaHandler::UploadMedia complete. 
\end{lstlisting}

\subsection{Trace Summarization}

We do trace summarization at the granularity of a task. Thus, instead of summarizing the text representations of all the traces we want to summarize,
we instead summarize the text representations for each task across all traces. Thus, if a set of traces has 30 different tasks,
we perform 30 different multi-document summarizations to obtain a summary for each task. These task-specific summaries
are then concatenated together to form the summary of the traces.
The reason behind doing summarization at the granularity of a task is to ensure that there is no cross-contamination
of information between the tasks as we don't want the summarized result to have an incorrect text representation.
Additionally, the format of that summary will now match the overview generated for a
single trace. This allows us to then be able to make clean comparisons between a single trace and a group of traces using their summary.
Since each task has a relatively set behavior,
we can infer that the overview paragraphs describing it will never changes drastically during normal execution. Even though it may be repeated hundreds of times, 
there will not be an explosion in the number of unique sentences found across traces. This means that the 
summarization of a task does not have to be a complex operation.
We break down our summarization in three steps - Preprocessing, Graph Construction, and Text Conversion - that we describe below.

\fakepara{Preprocessing} In the preprocessing step, text representation for each trace is broken into text representations of each
task. Based on our text generation algorithm, text representation for a task in a trace is a paragraph.
Text representations from multiple traces are then grouped together by task. For each task, there are multiple
paragraphs that need to be summarized. Each such paragraph is represented as its own document such that
there are multiple documents available for each task.

\fakepara{Graph Construction} For each task, we construct an aggregate weighted graph from the documents associated with that task.
Each node in the graph represents one unique sentence across the documents. Uniqueness is defined not only by the content
of the sentence but also by the prefix of sentences that were before the sentence. This is done to ensure that
when the documents are being aggregated, two sentences are only merged together if they have the same preceding
sentences. Each edge represents the causal and temporal ordering between sentences. This is constructed by adding
an edge between each pair of adjacent sentences. The weight of the edge represents the number of documents in
which that edge was seen.

\fakepara{Text Conversion} To convert the graph into text we first create a topological sort ordering of the vertices
in the graph. This is to flatten the graph structure as the aggregation would have induced branches in the graph
because of deviations. We choose a topological sort ordering as it guarantees to preserve the order
between sentences from all the documents. Once we have the ordering, we simply concatenate the labels
from the nodes according to the ordering to generate the summary for that particular task.
Currently, we don't use the weights of the edges in the text generation.

\subsection{Trace Diff}

\begin{figure*}[tbh]
    \begin{equation}\label{eqn:disttrace}
    \texttt{distance} = \sum_{t \in T_1 \cup T_2} disttask(t)
    \end{equation}
    
    \begin{equation}\label{eqn:disttask}
        disttask(t)=
        \begin{cases}
            \texttt{Levenshtein}(t1, t2), \texttt{if}\: t \in T_1 \cap T_2, t1 \in T_1, t2 \in T_2 \\
            P * \texttt{numsentences}(t), \texttt{if}\: t \in (T_1 \setminus T_2) \cup (T_2 \setminus T_1).\\
        \end{cases}
    \end{equation}
    \end{figure*}

To compare two traces, or one trace and one aggregate set of traces, or two different aggregate sets of traces, we choose to compare their corresponding texts. For calculating the difference
between the two text representations, we use Google's diff-match-patch library\footnote{Library available at \url{https://github.com/google/diff-match-patch}}. For explaining our algorithm, we choose to explain the comparison
of two traces but the same algorithm applies for the other two comparison scenarios.
However, instead of just computing the diff between the two texts, we strive for a much finer granularity, and instead
compute the diff between the texts by computing the diffs between the common tasks amongst the two traces.
Tasks that are only present in either trace are automatically treated as insertions or deletions in the diff.
\autoref{fig:taskdiff} shows the output of the diff function applied to one common task in two traces.
The uncolored, normal text represents sentences (i.e. events) that are present in both traces. The struck-out,
red text represents the text that is only present in trace 1 but not in trace 2. The italic, green text represents
the text that is only present in trace 2 but not in trace 1.

% escapechar sets the escape character that we can use to exit into latex mode.
\begin{lstlisting}[caption={Text Difference for a task from 2 traces},captionpos=b,label={fig:taskdiff}, escapechar=\#]
    Task NginxWebServer created task MediaHandler::UploadMedia. MediaHandler::UploadMedia. Uploading media to compose post service. Popping client from client pool. Obtaining lock on client pool mutex. Obtained lock on client pool mutex. #\textcolor{red}{\sout{No client available in client pool. Creating a new client}}\textcolor{green}{\emph{Popping client from front of the pool}}#. Releasing lock on client pool mutex. Connecting to client. Pushing a client into client pool. Acquiring lock on mutex. Acquired lock on mutex. Pushing client back into client pool. Releasing lock on mutex. MediaHandler::UploadMedia complete
\end{lstlisting}

\fakepara{Trace Distance} Based on our diff function above, we also provide a new metric for calculating
the distance between any two traces. Let $T_1$ be the set of tasks in Trace 1 and $T_2$ be the set
of tasks in Trace 2. Then, the distance between the two traces is the sum of the distances for each task
in $T_1$ and $T_2$. \autoref{eqn:disttrace} shows the formal definition of the function for calculating
the distance between the text representations of two traces.
The disttask function for a task defines the distance calculated for this task between Trace 1 and Trace 2.
If the task is present in both the traces, then the cost is simply the Levenshtein distance between the paragraphs
for this task in the two traces. However, if the task is only present in one of the traces, then the distance is
the number of sentences in the paragraph for that task multiplied by some pre-defined task missing penalty, $P$.
Currently, $P$ is set to 10 but can be changed depending on the needs of the users. \autoref{eqn:disttask}
shows the formal definition for calculating the distance between the text representations of a task in two traces.
